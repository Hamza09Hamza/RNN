{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Modélisation\n",
    "\n",
    "Dans cette section, nous allons entamer la phase de modélisation, qui consiste à :\n",
    "\n",
    "- Choisir un ou plusieurs modèles adaptés au type de problème (classification ou régression),\n",
    "- Entraîner ces modèles sur l’ensemble d’apprentissage,\n",
    "- Optimiser leurs performances à l’aide de la validation croisée et de la recherche d’hyperparamètres (GridSearchCV, RandomizedSearchCV).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Path_Data='../Data/Processed/'\n",
    "X_train = pd.read_csv(Path_Data+'X_train.csv')\n",
    "X_val = pd.read_csv(Path_Data+'X_val.csv')\n",
    "X_test = pd.read_csv(Path_Data+'X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv(Path_Data+'y_train.csv')\n",
    "y_val = pd.read_csv(Path_Data+'y_val.csv')\n",
    "y_test = pd.read_csv(Path_Data+'y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des Modèles \n",
    "\n",
    "Nous allons utiliser les modèles suivants pour nos tâches de classification et régression :\n",
    "\n",
    "- **CatBoost**\n",
    "- **LightGBM (LGBM)**\n",
    "- **XGBoost**\n",
    "- **Forêt Aléatoire (Random Forest)**\n",
    "- **KNN (K-Nearest Neighbors)**\n",
    "- Et d'autres modèles selon les besoins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from LogisticRegression import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\":XGBClassifier(),\n",
    "    \"CatBoost\":CatBoostClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On definie les Grids de Parametres Pour chaque model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'alpha': [0.001, 0.01, 0.1],\n",
    "        'iterations': [500, 1000],\n",
    "        'use_l2': [True, False],\n",
    "        'lambda_': [0.01, 0.1, 1.0],\n",
    "        'use_decay': [True, False],\n",
    "        'decay': [0.001, 0.01, 0.1],\n",
    "        'early_stopping': [True, False],\n",
    "        'tol': [1e-4, 1e-5]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [50, 100, 200]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [500, 1000],\n",
    "        'depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [50, 100, 200]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "best_model_results = {\"model_name\": [], \"best_params\": [], \"val_accuracy\": []}\n",
    "best_overall = {\"model_name\": None, \"val_accuracy\": 0.0, \"best_params\": None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Détection de l’environnement d'exécution (CPU, GPU NVIDIA, ou puce Apple M1/M2..)\n",
    "\n",
    "Ce script Python permet de **détecter automatiquement** l'environnement matériel sur lequel votre code est exécuté, afin d’adapter l'entraînement des modèles (par exemple : activer l’utilisation du GPU quand c’est possible).\n",
    "Dans Notre Cas on a deux Puissante Machine l'une avec M1 Pro  et l'autre avec une Carte Graphique RTX 4070  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "\n",
    "def detect_environment():\n",
    "    system = platform.system().lower()\n",
    "    machine = platform.machine().lower()\n",
    "\n",
    "    # Apple Silicons (M1/M2)\n",
    "    if system == 'darwin' and 'arm' in machine:\n",
    "        return \"M1\"\n",
    "\n",
    "    # CUDA-compatible NVIDIA GPU\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        if result.returncode == 0:\n",
    "            return \"CUDA\"\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    return \"CPU\"\n",
    "\n",
    "env = detect_environment()\n",
    "print(f\" Environnement détecté : {env}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Optimisation des hyperparamètres avec GridSearchCV et accélération GPU\n",
    "\n",
    "Pour garantir les meilleures performances de chaque modèle de classification, nous utilisons **GridSearchCV** pour effectuer un réglage fin des hyperparamètres. Voici les étapes :\n",
    "\n",
    "1. **Exclusion des modèles personnalisés** :\n",
    "   - Le modèle de régression logistique implémenté manuellement est exclu car il ne prend pas en charge `GridSearchCV` directement.\n",
    "\n",
    "2. **Utilisation complète du CPU et du GPU** :\n",
    "   - `n_jobs = -1` permet d’utiliser tous les cœurs du processeur pour les calculs parallèles.\n",
    "   - Pour les modèles compatibles avec le GPU, nous activons explicitement l'accélération :\n",
    "     - **XGBoost** : `tree_method='gpu_hist'`\n",
    "     - **LightGBM** : `device='gpu'`\n",
    "     - **CatBoost** : `task_type='GPU'`, `devices='0'`\n",
    "\n",
    "3. **Affichage détaillé de l'entraînement** :\n",
    "   - `verbose=2` affiche les étapes détaillées de l'entraînement, ce qui permet de suivre la progression en temps réel.\n",
    "\n",
    "4. **Validation croisée** :\n",
    "   - Une validation croisée à 3 plis (`cv=3`) est utilisée pour éviter le surapprentissage et améliorer la robustesse de la sélection des modèles.\n",
    "\n",
    "5. **Évaluation** :\n",
    "   - Après l'entraînement, nous extrayons les meilleurs hyperparamètres et évaluons le modèle sur l'ensemble de validation à l’aide de la précision (`accuracy`).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import os\n",
    "\n",
    "env = detect_environment()\n",
    "print(f\" Environnement détecté : {env}\")\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = \"./model_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Initialize results file\n",
    "results_file = os.path.join(results_dir, \"model_results.json\")\n",
    "if not os.path.exists(results_file):\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump({\"models\": []}, f)\n",
    "\n",
    "# Load existing results\n",
    "with open(results_file, 'r') as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "# Track best overall model\n",
    "best_overall_model = {\n",
    "    \"model_name\": None,\n",
    "    \"best_params\": None,\n",
    "    \"val_accuracy\": 0.0\n",
    "}\n",
    "\n",
    "def save_model_result(model_name, best_params, val_accuracy):\n",
    "    \"\"\"Save the result of a single model to the JSON file\"\"\"\n",
    "    model_result = {\n",
    "        \"model_name\": model_name,\n",
    "        \"best_params\": best_params,\n",
    "        \"val_accuracy\": val_accuracy\n",
    "    }\n",
    "    \n",
    "    # Update all_results\n",
    "    all_results[\"models\"].append(model_result)\n",
    "    \n",
    "    # Update best overall model\n",
    "    global best_overall_model\n",
    "    if val_accuracy > best_overall_model[\"val_accuracy\"]:\n",
    "        best_overall_model = model_result.copy()\n",
    "    \n",
    "    # Save to file\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n✅ Results for {model_name} saved to {results_file}\")\n",
    "\n",
    "def wait_for_input(model_name):\n",
    "    \"\"\"Wait for user input before proceeding to next model\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Completed training for {model_name}\")\n",
    "    print(\"Press Enter to continue to next model or 'q' to quit...\")\n",
    "    user_input = input()\n",
    "    if user_input.lower() == 'q':\n",
    "        print(\"\\nExiting early...\")\n",
    "        print_summary()\n",
    "        exit()\n",
    "\n",
    "def print_summary():\n",
    "    \"\"\"Print summary of all results\"\"\"\n",
    "    print(\"\\n\\n📊 Final Summary of Results:\")\n",
    "    for model in all_results[\"models\"]:\n",
    "        print(f\"\\n{model['model_name']}:\")\n",
    "        print(f\"  Validation Accuracy: {model['val_accuracy']:.4f}\")\n",
    "        print(f\"  Best Parameters: {model['best_params']}\")\n",
    "    \n",
    "    print(\"\\n🏆 Best Overall Model:\")\n",
    "    if best_overall_model[\"model_name\"]:\n",
    "        print(f\"{best_overall_model['model_name']} with accuracy {best_overall_model['val_accuracy']:.4f}\")\n",
    "        print(f\"Parameters: {best_overall_model['best_params']}\")\n",
    "    else:\n",
    "        print(\"No models completed yet.\")\n",
    "\n",
    "def setup_gpu_for_model(model, model_name):\n",
    "    \"\"\"Properly configure GPU settings for each model\"\"\"\n",
    "    if env == \"CUDA\":\n",
    "        if model_name == \"XGBoost\":\n",
    "            model.set_params(\n",
    "                tree_method='hist',\n",
    "                device='cuda:0'\n",
    "            )\n",
    "        elif model_name == \"LightGBM\":\n",
    "            model.set_params(\n",
    "                device='gpu',\n",
    "                gpu_platform_id=0,\n",
    "                gpu_device_id=0\n",
    "            )\n",
    "        elif model_name == \"CatBoost\":\n",
    "            model.set_params(\n",
    "                task_type='GPU',\n",
    "                devices='0:0',\n",
    "                verbose=0\n",
    "            )\n",
    "  \n",
    "    elif env == \"M1\":\n",
    "        if model_name == \"LightGBM\":\n",
    "            model.set_params(device_type='metal')\n",
    "        elif model_name == \"CatBoost\":\n",
    "            model.set_params(task_type='CPU', verbose=0)\n",
    "    else:  # CPU fallback\n",
    "        if model_name == \"XGBoost\":\n",
    "            model.set_params(tree_method='hist', device='cpu')\n",
    "        elif model_name == \"LightGBM\":\n",
    "            model.set_params(device_type='cpu')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def monitor_gpu():\n",
    "    try:\n",
    "        if env == \"CUDA\":\n",
    "            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
    "            print(\"GPU Usage:\\n\", result.stdout.decode())\n",
    "    except:\n",
    "        print(\"Could not monitor GPU usage\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"🚀 Starting GridSearch for: {model_name}\")\n",
    "   \n",
    "    # Proper GPU setup\n",
    "    model = setup_gpu_for_model(model, model_name)\n",
    "    \n",
    "    # Monitor before training\n",
    "    monitor_gpu()\n",
    "    \n",
    "    try:\n",
    "        # Special handling for SVM if using cuML\n",
    "\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=3,\n",
    "            n_jobs=1,  # Keep this as 1 for GPU models\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Prepare data - convert to numpy arrays properly\n",
    "        if env == \"CUDA\" and model_name in [\"XGBoost\", \"LightGBM\", \"CatBoost\"]:\n",
    "            X_train_gpu = X_train.values.astype(np.float32)  # Proper conversion\n",
    "            y_train_gpu = y_train.values.astype(np.float32).ravel()\n",
    "            \n",
    "            # For validation data too\n",
    "            X_val_gpu = X_val.values.astype(np.float32)\n",
    "            y_val_gpu = y_val.values.astype(np.float32).ravel()\n",
    "            \n",
    "            grid_search.fit(X_train_gpu, y_train_gpu)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_val = best_model.predict(X_val_gpu)  # Predict on GPU data\n",
    "            val_acc = accuracy_score(y_val_gpu, y_pred_val)\n",
    "        else:\n",
    "            # For CPU models\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_val = best_model.predict(X_val)\n",
    "            val_acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        # Monitor after training\n",
    "        monitor_gpu()\n",
    "        \n",
    "        print(f\"\\n🎯 Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"📊 {model_name} - Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        save_model_result(model_name, grid_search.best_params_, val_acc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error training {model_name}: {str(e)}\")\n",
    "        save_model_result(model_name, {\"error\": str(e)}, 0.0)\n",
    "    \n",
    "    if env == \"CUDA\":\n",
    "        import gc\n",
    "        del grid_search\n",
    "        gc.collect()\n",
    "    \n",
    "    wait_for_input(model_name)\n",
    "\n",
    "print_summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
