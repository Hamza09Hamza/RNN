{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Mod√©lisation\n",
    "\n",
    "Dans cette section, nous allons entamer la phase de mod√©lisation, qui consiste √† :\n",
    "\n",
    "- Choisir un ou plusieurs mod√®les adapt√©s au type de probl√®me (classification ou r√©gression),\n",
    "- Entra√Æner ces mod√®les sur l‚Äôensemble d‚Äôapprentissage,\n",
    "- Optimiser leurs performances √† l‚Äôaide de la validation crois√©e et de la recherche d‚Äôhyperparam√®tres (GridSearchCV, RandomizedSearchCV).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Path_Data='../Data/Processed/'\n",
    "X_train = pd.read_csv(Path_Data+'X_train.csv')\n",
    "X_val = pd.read_csv(Path_Data+'X_val.csv')\n",
    "X_test = pd.read_csv(Path_Data+'X_test.csv')\n",
    "\n",
    "y_train = pd.read_csv(Path_Data+'y_train.csv')\n",
    "y_val = pd.read_csv(Path_Data+'y_val.csv')\n",
    "y_test = pd.read_csv(Path_Data+'y_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des Mod√®les \n",
    "\n",
    "Nous allons utiliser les mod√®les suivants pour nos t√¢ches de classification et r√©gression :\n",
    "\n",
    "- **CatBoost**\n",
    "- **LightGBM (LGBM)**\n",
    "- **XGBoost**\n",
    "- **For√™t Al√©atoire (Random Forest)**\n",
    "- **KNN (K-Nearest Neighbors)**\n",
    "- Et d'autres mod√®les selon les besoins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from LogisticRegression import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"XGBoost\":XGBClassifier(),\n",
    "    \"CatBoost\":CatBoostClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### On definie les Grids de Parametres Pour chaque model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'alpha': [0.001, 0.01, 0.1],\n",
    "        'iterations': [500, 1000],\n",
    "        'use_l2': [True, False],\n",
    "        'lambda_': [0.01, 0.1, 1.0],\n",
    "        'use_decay': [True, False],\n",
    "        'decay': [0.001, 0.01, 0.1],\n",
    "        'early_stopping': [True, False],\n",
    "        'tol': [1e-4, 1e-5]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [50, 100, 200]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [500, 1000],\n",
    "        'depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, 30, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [50, 100, 200]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "best_model_results = {\"model_name\": [], \"best_params\": [], \"val_accuracy\": []}\n",
    "best_overall = {\"model_name\": None, \"val_accuracy\": 0.0, \"best_params\": None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  D√©tection de l‚Äôenvironnement d'ex√©cution (CPU, GPU NVIDIA, ou puce Apple M1/M2..)\n",
    "\n",
    "Ce script Python permet de **d√©tecter automatiquement** l'environnement mat√©riel sur lequel votre code est ex√©cut√©, afin d‚Äôadapter l'entra√Ænement des mod√®les (par exemple : activer l‚Äôutilisation du GPU quand c‚Äôest possible).\n",
    "Dans Notre Cas on a deux Puissante Machine l'une avec M1 Pro  et l'autre avec une Carte Graphique RTX 4070  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "\n",
    "def detect_environment():\n",
    "    system = platform.system().lower()\n",
    "    machine = platform.machine().lower()\n",
    "\n",
    "    # Apple Silicons (M1/M2)\n",
    "    if system == 'darwin' and 'arm' in machine:\n",
    "        return \"M1\"\n",
    "\n",
    "    # CUDA-compatible NVIDIA GPU\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        if result.returncode == 0:\n",
    "            return \"CUDA\"\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    return \"CPU\"\n",
    "\n",
    "env = detect_environment()\n",
    "print(f\" Environnement d√©tect√© : {env}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Optimisation des hyperparam√®tres avec GridSearchCV et acc√©l√©ration GPU\n",
    "\n",
    "Pour garantir les meilleures performances de chaque mod√®le de classification, nous utilisons **GridSearchCV** pour effectuer un r√©glage fin des hyperparam√®tres. Voici les √©tapes :\n",
    "\n",
    "1. **Exclusion des mod√®les personnalis√©s** :\n",
    "   - Le mod√®le de r√©gression logistique impl√©ment√© manuellement est exclu car il ne prend pas en charge `GridSearchCV` directement.\n",
    "\n",
    "2. **Utilisation compl√®te du CPU et du GPU** :\n",
    "   - `n_jobs = -1` permet d‚Äôutiliser tous les c≈ìurs du processeur pour les calculs parall√®les.\n",
    "   - Pour les mod√®les compatibles avec le GPU, nous activons explicitement l'acc√©l√©ration :\n",
    "     - **XGBoost** : `tree_method='gpu_hist'`\n",
    "     - **LightGBM** : `device='gpu'`\n",
    "     - **CatBoost** : `task_type='GPU'`, `devices='0'`\n",
    "\n",
    "3. **Affichage d√©taill√© de l'entra√Ænement** :\n",
    "   - `verbose=2` affiche les √©tapes d√©taill√©es de l'entra√Ænement, ce qui permet de suivre la progression en temps r√©el.\n",
    "\n",
    "4. **Validation crois√©e** :\n",
    "   - Une validation crois√©e √† 3 plis (`cv=3`) est utilis√©e pour √©viter le surapprentissage et am√©liorer la robustesse de la s√©lection des mod√®les.\n",
    "\n",
    "5. **√âvaluation** :\n",
    "   - Apr√®s l'entra√Ænement, nous extrayons les meilleurs hyperparam√®tres et √©valuons le mod√®le sur l'ensemble de validation √† l‚Äôaide de la pr√©cision (`accuracy`).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import subprocess\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import os\n",
    "\n",
    "env = detect_environment()\n",
    "print(f\" Environnement d√©tect√© : {env}\")\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = \"./model_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Initialize results file\n",
    "results_file = os.path.join(results_dir, \"model_results.json\")\n",
    "if not os.path.exists(results_file):\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump({\"models\": []}, f)\n",
    "\n",
    "# Load existing results\n",
    "with open(results_file, 'r') as f:\n",
    "    all_results = json.load(f)\n",
    "\n",
    "# Track best overall model\n",
    "best_overall_model = {\n",
    "    \"model_name\": None,\n",
    "    \"best_params\": None,\n",
    "    \"val_accuracy\": 0.0\n",
    "}\n",
    "\n",
    "def save_model_result(model_name, best_params, val_accuracy):\n",
    "    \"\"\"Save the result of a single model to the JSON file\"\"\"\n",
    "    model_result = {\n",
    "        \"model_name\": model_name,\n",
    "        \"best_params\": best_params,\n",
    "        \"val_accuracy\": val_accuracy\n",
    "    }\n",
    "    \n",
    "    # Update all_results\n",
    "    all_results[\"models\"].append(model_result)\n",
    "    \n",
    "    # Update best overall model\n",
    "    global best_overall_model\n",
    "    if val_accuracy > best_overall_model[\"val_accuracy\"]:\n",
    "        best_overall_model = model_result.copy()\n",
    "    \n",
    "    # Save to file\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Results for {model_name} saved to {results_file}\")\n",
    "\n",
    "def wait_for_input(model_name):\n",
    "    \"\"\"Wait for user input before proceeding to next model\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Completed training for {model_name}\")\n",
    "    print(\"Press Enter to continue to next model or 'q' to quit...\")\n",
    "    user_input = input()\n",
    "    if user_input.lower() == 'q':\n",
    "        print(\"\\nExiting early...\")\n",
    "        print_summary()\n",
    "        exit()\n",
    "\n",
    "def print_summary():\n",
    "    \"\"\"Print summary of all results\"\"\"\n",
    "    print(\"\\n\\nüìä Final Summary of Results:\")\n",
    "    for model in all_results[\"models\"]:\n",
    "        print(f\"\\n{model['model_name']}:\")\n",
    "        print(f\"  Validation Accuracy: {model['val_accuracy']:.4f}\")\n",
    "        print(f\"  Best Parameters: {model['best_params']}\")\n",
    "    \n",
    "    print(\"\\nüèÜ Best Overall Model:\")\n",
    "    if best_overall_model[\"model_name\"]:\n",
    "        print(f\"{best_overall_model['model_name']} with accuracy {best_overall_model['val_accuracy']:.4f}\")\n",
    "        print(f\"Parameters: {best_overall_model['best_params']}\")\n",
    "    else:\n",
    "        print(\"No models completed yet.\")\n",
    "\n",
    "def setup_gpu_for_model(model, model_name):\n",
    "    \"\"\"Properly configure GPU settings for each model\"\"\"\n",
    "    if env == \"CUDA\":\n",
    "        if model_name == \"XGBoost\":\n",
    "            model.set_params(\n",
    "                tree_method='hist',\n",
    "                device='cuda:0'\n",
    "            )\n",
    "        elif model_name == \"LightGBM\":\n",
    "            model.set_params(\n",
    "                device='gpu',\n",
    "                gpu_platform_id=0,\n",
    "                gpu_device_id=0\n",
    "            )\n",
    "        elif model_name == \"CatBoost\":\n",
    "            model.set_params(\n",
    "                task_type='GPU',\n",
    "                devices='0:0',\n",
    "                verbose=0\n",
    "            )\n",
    "  \n",
    "    elif env == \"M1\":\n",
    "        if model_name == \"LightGBM\":\n",
    "            model.set_params(device_type='metal')\n",
    "        elif model_name == \"CatBoost\":\n",
    "            model.set_params(task_type='CPU', verbose=0)\n",
    "    else:  # CPU fallback\n",
    "        if model_name == \"XGBoost\":\n",
    "            model.set_params(tree_method='hist', device='cpu')\n",
    "        elif model_name == \"LightGBM\":\n",
    "            model.set_params(device_type='cpu')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def monitor_gpu():\n",
    "    try:\n",
    "        if env == \"CUDA\":\n",
    "            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n",
    "            print(\"GPU Usage:\\n\", result.stdout.decode())\n",
    "    except:\n",
    "        print(\"Could not monitor GPU usage\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üöÄ Starting GridSearch for: {model_name}\")\n",
    "   \n",
    "    # Proper GPU setup\n",
    "    model = setup_gpu_for_model(model, model_name)\n",
    "    \n",
    "    # Monitor before training\n",
    "    monitor_gpu()\n",
    "    \n",
    "    try:\n",
    "        # Special handling for SVM if using cuML\n",
    "\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=3,\n",
    "            n_jobs=1,  # Keep this as 1 for GPU models\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        # Prepare data - convert to numpy arrays properly\n",
    "        if env == \"CUDA\" and model_name in [\"XGBoost\", \"LightGBM\", \"CatBoost\"]:\n",
    "            X_train_gpu = X_train.values.astype(np.float32)  # Proper conversion\n",
    "            y_train_gpu = y_train.values.astype(np.float32).ravel()\n",
    "            \n",
    "            # For validation data too\n",
    "            X_val_gpu = X_val.values.astype(np.float32)\n",
    "            y_val_gpu = y_val.values.astype(np.float32).ravel()\n",
    "            \n",
    "            grid_search.fit(X_train_gpu, y_train_gpu)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_val = best_model.predict(X_val_gpu)  # Predict on GPU data\n",
    "            val_acc = accuracy_score(y_val_gpu, y_pred_val)\n",
    "        else:\n",
    "            # For CPU models\n",
    "            grid_search.fit(X_train, y_train)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            y_pred_val = best_model.predict(X_val)\n",
    "            val_acc = accuracy_score(y_val, y_pred_val)\n",
    "\n",
    "        # Monitor after training\n",
    "        monitor_gpu()\n",
    "        \n",
    "        print(f\"\\nüéØ Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "        print(f\"üìä {model_name} - Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        save_model_result(model_name, grid_search.best_params_, val_acc)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error training {model_name}: {str(e)}\")\n",
    "        save_model_result(model_name, {\"error\": str(e)}, 0.0)\n",
    "    \n",
    "    if env == \"CUDA\":\n",
    "        import gc\n",
    "        del grid_search\n",
    "        gc.collect()\n",
    "    \n",
    "    wait_for_input(model_name)\n",
    "\n",
    "print_summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
